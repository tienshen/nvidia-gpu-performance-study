{"Layers": [{
  "Name": "__myl_Move_myl0_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 119) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.0/attention/Div]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.0/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast]"
},{
  "Name": "__myl_Move_myl0_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 116) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.0/attention/Div]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.0/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.0/attention/Cast]"
},{
  "Name": "__myl_ReshCastReplSubCastSele_myl0_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "attention_mask",
    "Dimensions": [1,128],
    "Format/Datatype": "Int64"
  }],
  "Outputs": [
  {
    "Name": "/Where_1_output_0",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_ReshCastReplSubCastSele_0xfae0f98219aadb858f15676a2fae7018",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /Unsqueeze]\u001e[ONNX Layer: /Unsqueeze_1]\u001f[ONNX Layer: /Cast]\u001f[ONNX Layer: /Cast_1]\u001f[ONNX Layer: /Where_1]\u001f[ONNX Layer: /Sub]"
},{
  "Name": "__myl_CastGathGathAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl0_3",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "input_ids",
    "Dimensions": [1,128],
    "Format/Datatype": "Int64"
  }],
  "Outputs": [
  {
    "Name": "/embeddings/LayerNorm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_CastGathGathAddMeanSubMulMeanAddSqrtDivMulMulAdd_0xe09eccc392b465e4301acc6dbcdca438",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /embeddings/word_embeddings/Gather]\u001f[ONNX Layer: /embeddings/LayerNorm/ReduceMean_1]\u001f[ONNX Layer: /embeddings/LayerNorm/Sub]\u001f[ONNX Layer: /embeddings/LayerNorm/Pow]\u001f[ONNX Layer: /embeddings/LayerNorm/ReduceMean]\u001f[ONNX Layer: /embeddings/Add]\u001f[ONNX Layer: /embeddings/position_embeddings/Gather]\u001f[ONNX Layer: /embeddings/LayerNorm/Div]\u001f[ONNX Layer: /embeddings/LayerNorm/Add_1]\u001f[ONNX Layer: /embeddings/LayerNorm/Mul]\u001f[ONNX Layer: /embeddings/LayerNorm/Sqrt]\u001f[ONNX Layer: /embeddings/LayerNorm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/embeddings/LayerNorm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.0/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.0/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/Reshape_2 + /transformer/layer.0/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.0/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/Reshape + /transformer/layer.0/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.0/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.0/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 116) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/Reshape_1 + /transformer/layer.0/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/v_lin/MatMul + /transformer/layer.0/attention/v_lin/Add || /transformer/layer.0/attention/k_lin/MatMul + /transformer/layer.0/attention/k_lin/Add || /transformer/layer.0/attention/q_lin/MatMul + /transformer/layer.0/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.0/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.0/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.0/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.0/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.0/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.0/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 119) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.0/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.0/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.0/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.0/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Add]"
},{
  "Name": "/transformer/layer.0/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 123) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Softmax]"
},{
  "Name": "/transformer/layer.0/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 123) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.0/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.0/attention/Transpose_3 + /transformer/layer.0/attention/Reshape_3 + reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/Transpose_3 + /transformer/layer.0/attention/Reshape_3 + reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/attention/Transpose_3 + /transformer/layer.0/attention/Reshape_3 + reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/Transpose_3 + /transformer/layer.0/attention/Reshape_3 + reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.0/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.0/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.0/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl23_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/embeddings/LayerNorm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.0/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.0/Add]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.0/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.0/ffn/lin1/MatMul + /transformer/layer.0/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/ffn/lin1/MatMul + /transformer/layer.0/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/ffn/lin1/MatMul + /transformer/layer.0/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/ffn/lin1/MatMul + /transformer/layer.0/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.0/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.0/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.0/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_93, PWN(/transformer/layer.0/ffn/activation/Mul_1)), PWN(/transformer/layer.0/ffn/activation/Mul_2)), PWN(/transformer/layer.0/ffn/activation/Mul_3)), PWN(/transformer/layer.0/ffn/activation/Add)), PWN(/transformer/layer.0/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_95, PWN(/transformer/layer.0/ffn/activation/Mul_4))), PWN(/transformer/layer.0/ffn/activation/Tanh)), PWN(/transformer/layer.0/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_97, PWN(/transformer/layer.0/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.0/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_91, PWN(/transformer/layer.0/ffn/activation/Mul)), PWN(/transformer/layer.0/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.0/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.0/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.0/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.0/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.0/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.0/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin2/MatMul]"
},{
  "Name": "__myl_Move_myl36_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 266) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.1/attention/Div]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.1/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast]"
},{
  "Name": "__myl_Move_myl36_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 263) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.1/attention/Div]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.1/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.1/attention/Cast]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl36_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.0/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.0/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.0/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.0/Add_1]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.0/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/output_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.1/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.1/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/Reshape_2 + /transformer/layer.1/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.1/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/Reshape + /transformer/layer.1/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.1/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.1/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 263) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/Reshape_1 + /transformer/layer.1/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/v_lin/MatMul + /transformer/layer.1/attention/v_lin/Add || /transformer/layer.1/attention/k_lin/MatMul + /transformer/layer.1/attention/k_lin/Add || /transformer/layer.1/attention/q_lin/MatMul + /transformer/layer.1/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.1/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.1/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.1/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.1/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.1/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.1/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 266) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.1/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.1/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.1/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.1/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Add]"
},{
  "Name": "/transformer/layer.1/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 270) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Softmax]"
},{
  "Name": "/transformer/layer.1/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 270) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.1/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.1/attention/Transpose_3 + /transformer/layer.1/attention/Reshape_3 + reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/Transpose_3 + /transformer/layer.1/attention/Reshape_3 + reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/attention/Transpose_3 + /transformer/layer.1/attention/Reshape_3 + reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/Transpose_3 + /transformer/layer.1/attention/Reshape_3 + reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.1/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.1/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.1/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl59_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.0/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.1/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.1/Add]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.1/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.1/ffn/lin1/MatMul + /transformer/layer.1/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/ffn/lin1/MatMul + /transformer/layer.1/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/ffn/lin1/MatMul + /transformer/layer.1/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/ffn/lin1/MatMul + /transformer/layer.1/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.1/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.1/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.1/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_183, PWN(/transformer/layer.1/ffn/activation/Mul_1)), PWN(/transformer/layer.1/ffn/activation/Mul_2)), PWN(/transformer/layer.1/ffn/activation/Mul_3)), PWN(/transformer/layer.1/ffn/activation/Add)), PWN(/transformer/layer.1/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_185, PWN(/transformer/layer.1/ffn/activation/Mul_4))), PWN(/transformer/layer.1/ffn/activation/Tanh)), PWN(/transformer/layer.1/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_187, PWN(/transformer/layer.1/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.1/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_181, PWN(/transformer/layer.1/ffn/activation/Mul)), PWN(/transformer/layer.1/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.1/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.1/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.1/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.1/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.1/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.1/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin2/MatMul]"
},{
  "Name": "__myl_Move_myl72_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 413) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.2/attention/Div]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.2/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast]"
},{
  "Name": "__myl_Move_myl72_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 410) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.2/attention/Div]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.2/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.2/attention/Cast]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl72_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.1/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.1/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.1/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.1/Add_1]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.1/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/output_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.2/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.2/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/Reshape_2 + /transformer/layer.2/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.2/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/Reshape + /transformer/layer.2/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.2/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.2/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 410) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/Reshape_1 + /transformer/layer.2/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/v_lin/MatMul + /transformer/layer.2/attention/v_lin/Add || /transformer/layer.2/attention/k_lin/MatMul + /transformer/layer.2/attention/k_lin/Add || /transformer/layer.2/attention/q_lin/MatMul + /transformer/layer.2/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.2/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.2/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.2/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.2/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.2/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.2/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 413) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.2/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.2/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.2/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.2/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Add]"
},{
  "Name": "/transformer/layer.2/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 417) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Softmax]"
},{
  "Name": "/transformer/layer.2/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 417) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.2/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.2/attention/Transpose_3 + /transformer/layer.2/attention/Reshape_3 + reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/Transpose_3 + /transformer/layer.2/attention/Reshape_3 + reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/attention/Transpose_3 + /transformer/layer.2/attention/Reshape_3 + reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/Transpose_3 + /transformer/layer.2/attention/Reshape_3 + reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.2/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.2/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.2/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl95_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.1/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.2/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.2/Add]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.2/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.2/ffn/lin1/MatMul + /transformer/layer.2/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/ffn/lin1/MatMul + /transformer/layer.2/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/ffn/lin1/MatMul + /transformer/layer.2/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/ffn/lin1/MatMul + /transformer/layer.2/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.2/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.2/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.2/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_273, PWN(/transformer/layer.2/ffn/activation/Mul_1)), PWN(/transformer/layer.2/ffn/activation/Mul_2)), PWN(/transformer/layer.2/ffn/activation/Mul_3)), PWN(/transformer/layer.2/ffn/activation/Add)), PWN(/transformer/layer.2/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_275, PWN(/transformer/layer.2/ffn/activation/Mul_4))), PWN(/transformer/layer.2/ffn/activation/Tanh)), PWN(/transformer/layer.2/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_277, PWN(/transformer/layer.2/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.2/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_271, PWN(/transformer/layer.2/ffn/activation/Mul)), PWN(/transformer/layer.2/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.2/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.2/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.2/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.2/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.2/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.2/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin2/MatMul]"
},{
  "Name": "__myl_Move_myl108_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 560) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.3/attention/Div]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.3/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast]"
},{
  "Name": "__myl_Move_myl108_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 557) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.3/attention/Div]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.3/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.3/attention/Cast]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl108_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.2/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.2/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.2/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.2/Add_1]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.2/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/output_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.3/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.3/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/Reshape_2 + /transformer/layer.3/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.3/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/Reshape + /transformer/layer.3/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.3/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.3/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 557) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/Reshape_1 + /transformer/layer.3/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/v_lin/MatMul + /transformer/layer.3/attention/v_lin/Add || /transformer/layer.3/attention/k_lin/MatMul + /transformer/layer.3/attention/k_lin/Add || /transformer/layer.3/attention/q_lin/MatMul + /transformer/layer.3/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.3/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.3/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.3/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.3/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.3/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.3/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 560) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.3/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.3/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.3/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.3/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Add]"
},{
  "Name": "/transformer/layer.3/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 564) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Softmax]"
},{
  "Name": "/transformer/layer.3/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 564) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.3/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.3/attention/Transpose_3 + /transformer/layer.3/attention/Reshape_3 + reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/Transpose_3 + /transformer/layer.3/attention/Reshape_3 + reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/attention/Transpose_3 + /transformer/layer.3/attention/Reshape_3 + reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/Transpose_3 + /transformer/layer.3/attention/Reshape_3 + reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.3/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.3/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.3/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl131_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.2/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.3/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.3/Add]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.3/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.3/ffn/lin1/MatMul + /transformer/layer.3/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/ffn/lin1/MatMul + /transformer/layer.3/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/ffn/lin1/MatMul + /transformer/layer.3/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/ffn/lin1/MatMul + /transformer/layer.3/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.3/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.3/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.3/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_363, PWN(/transformer/layer.3/ffn/activation/Mul_1)), PWN(/transformer/layer.3/ffn/activation/Mul_2)), PWN(/transformer/layer.3/ffn/activation/Mul_3)), PWN(/transformer/layer.3/ffn/activation/Add)), PWN(/transformer/layer.3/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_365, PWN(/transformer/layer.3/ffn/activation/Mul_4))), PWN(/transformer/layer.3/ffn/activation/Tanh)), PWN(/transformer/layer.3/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_367, PWN(/transformer/layer.3/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.3/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_361, PWN(/transformer/layer.3/ffn/activation/Mul)), PWN(/transformer/layer.3/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.3/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.3/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.3/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.3/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.3/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.3/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin2/MatMul]"
},{
  "Name": "__myl_Move_myl144_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 707) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.4/attention/Div]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.4/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast]"
},{
  "Name": "__myl_Move_myl144_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 704) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.4/attention/Div]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.4/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.4/attention/Cast]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl144_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.3/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.3/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.3/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.3/Add_1]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.3/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/output_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.4/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.4/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/Reshape_2 + /transformer/layer.4/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.4/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/Reshape + /transformer/layer.4/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.4/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.4/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 704) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/Reshape_1 + /transformer/layer.4/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/v_lin/MatMul + /transformer/layer.4/attention/v_lin/Add || /transformer/layer.4/attention/k_lin/MatMul + /transformer/layer.4/attention/k_lin/Add || /transformer/layer.4/attention/q_lin/MatMul + /transformer/layer.4/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.4/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.4/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.4/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.4/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.4/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.4/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 707) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.4/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.4/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.4/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.4/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Add]"
},{
  "Name": "/transformer/layer.4/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 711) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Softmax]"
},{
  "Name": "/transformer/layer.4/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 711) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.4/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.4/attention/Transpose_3 + /transformer/layer.4/attention/Reshape_3 + reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/Transpose_3 + /transformer/layer.4/attention/Reshape_3 + reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/attention/Transpose_3 + /transformer/layer.4/attention/Reshape_3 + reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/Transpose_3 + /transformer/layer.4/attention/Reshape_3 + reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.4/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.4/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.4/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl167_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.3/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.4/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.4/Add]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.4/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.4/ffn/lin1/MatMul + /transformer/layer.4/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/ffn/lin1/MatMul + /transformer/layer.4/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/ffn/lin1/MatMul + /transformer/layer.4/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/ffn/lin1/MatMul + /transformer/layer.4/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.4/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.4/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.4/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_453, PWN(/transformer/layer.4/ffn/activation/Mul_1)), PWN(/transformer/layer.4/ffn/activation/Mul_2)), PWN(/transformer/layer.4/ffn/activation/Mul_3)), PWN(/transformer/layer.4/ffn/activation/Add)), PWN(/transformer/layer.4/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_455, PWN(/transformer/layer.4/ffn/activation/Mul_4))), PWN(/transformer/layer.4/ffn/activation/Tanh)), PWN(/transformer/layer.4/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_457, PWN(/transformer/layer.4/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.4/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_451, PWN(/transformer/layer.4/ffn/activation/Mul)), PWN(/transformer/layer.4/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.4/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.4/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.4/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.4/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.4/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.4/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin2/MatMul]"
},{
  "Name": "__myl_Move_myl180_0",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 854) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Sqrt_2]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.5/attention/Div]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.5/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast]"
},{
  "Name": "__myl_Move_myl180_1",
  "LayerType": "kgen",
  "Inputs": [],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 851) [Shuffle]_output",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_Move_0xa1b840179a7b9d57f01d52d81c18f3ca",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Sqrt_1]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast_2]\u001f[ONNX Layer: /transformer/layer.5/attention/Div]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast_1]\u001f[ONNX Layer: /transformer/layer.5/attention/Sqrt]\u001f[ONNX Layer: /transformer/layer.5/attention/Cast]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl180_2",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.4/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.4/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.4/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.4/Add_1]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.4/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/output_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/v_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/attention/v_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 2304,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 1769472},
  "Bias": {"Type": "Float", "Count": 2304},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/v_lin/Add]\u001e[ONNX Layer: /transformer/layer.5/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/k_lin/Add]\u001e[ONNX Layer: /transformer/layer.5/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/q_lin/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to /transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,2304,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/Reshape_2 + /transformer/layer.5/attention/Transpose_1",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/v_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/Reshape_2]\u001e[ONNX Layer: /transformer/layer.5/attention/Transpose_1]"
},{
  "Name": "reshape_after_/transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/Reshape + /transformer/layer.5/attention/Transpose",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,1,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/q_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/Reshape]\u001e[ONNX Layer: /transformer/layer.5/attention/Transpose]"
},{
  "Name": "PWN(/transformer/layer.5/attention/Mul)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/Transpose_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 851) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x0000000000000002",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Mul]"
},{
  "Name": "reshape_after_/transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/Reshape_1 + /transformer/layer.5/attention/Transpose_2",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/v_lin/MatMul + /transformer/layer.5/attention/v_lin/Add || /transformer/layer.5/attention/k_lin/MatMul + /transformer/layer.5/attention/k_lin/Add || /transformer/layer.5/attention/q_lin/MatMul + /transformer/layer.5/attention/q_lin/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Channel major FP32 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,1,2,3],
  "Reshape": [1,-1,12,64],
  "SecondTranspose": [0,2,3,1],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/k_lin/MatMul]\u001e[ONNX Layer: /transformer/layer.5/attention/Reshape_1]\u001e[ONNX Layer: /transformer/layer.5/attention/Transpose_2]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to PWN(/transformer/layer.5/attention/Mul_1)",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/Transpose_2_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.5/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/transformer/layer.5/attention/Mul_1)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to PWN(/transformer/layer.5/attention/Mul_1)",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "(Unnamed Layer* 854) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, arg1);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Mul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 1 to /transformer/layer.5/attention/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/Mul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.5/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/attention/MatMul",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/Mul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "Reformatted Input Tensor 1 to /transformer/layer.5/attention/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,64,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x00000000000202a1",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/MatMul]"
},{
  "Name": "PWN(/transformer/layer.5/attention/Add)",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/Where_1_output_0",
    "Location": "Device",
    "Dimensions": [1,1,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 2,
  "InputArgs": ["arg0", "arg1"],
  "NbOutputVars": 1,
  "OutputVars": ["var0"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 0,
  "Literals": [],
  "NbOperations": 1,
  "Operations": ["auto const var0 = pwgen::iPlus(arg0, arg1);"],
  "TacticValue": "0x0000000000000006",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Add]"
},{
  "Name": "/transformer/layer.5/attention/Softmax",
  "LayerType": "CaskSoftMaxV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 858) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "SoftMax",
  "Axes": 8,
  "HasLog": 0,
  "TacticValue": "0x6d55c70c4c781969",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Softmax]"
},{
  "Name": "/transformer/layer.5/attention/MatMul_1",
  "LayerType": "CaskGemmMatrixMultiply",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 858) [Softmax]_output",
    "Location": "Device",
    "Dimensions": [1,12,128,128],
    "Format/Datatype": "Row major linear FP32"
  },
  {
    "Name": "/transformer/layer.5/attention/Transpose_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "ParameterType": "MatrixMultiply",
  "MatrixOpA": "NONE",
  "MatrixOpB": "NONE",
  "Alpha": {"Type": "", "Count": 0},
  "Beta": {"Type": "", "Count": 0},
  "TacticName": "sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x64x64_stage3_warpsize2x2x1_tensor16x8x8",
  "TacticValue": "0x000000000002034c",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/MatMul_1]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.5/attention/Transpose_3 + /transformer/layer.5/attention/Reshape_3 + reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/MatMul_1_output_0",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/Transpose_3 + /transformer/layer.5/attention/Reshape_3 + reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/attention/Transpose_3 + /transformer/layer.5/attention/Reshape_3 + reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "Shuffle",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/Transpose_3 + /transformer/layer.5/attention/Reshape_3 + reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [1,12,128,64],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Shuffle",
  "FirstTranspose": [0,2,1,3],
  "Reshape": [128,768,1,1],
  "SecondTranspose": [0,1,2,3],
  "ZeroIsPlaceholder": 0,
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/Transpose_3]\u001e[ONNX Layer: /transformer/layer.5/attention/Reshape_3]\u001e[ONNX Layer: /transformer/layer.5/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 589824},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1",
  "TacticValue": "0xa71946688cad8664",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/out_lin/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/attention/out_lin/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.5/attention/out_lin/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/attention/out_lin/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/attention/out_lin/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/out_lin/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl203_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.4/output_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.5/attention/out_lin/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/attention/out_lin/Add]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.5/Add]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.5/sa_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/sa_layer_norm/Add_1_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin1/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.5/ffn/lin1/MatMul + /transformer/layer.5/ffn/lin1/Add",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/ffn/lin1/MatMul + /transformer/layer.5/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/ffn/lin1/MatMul + /transformer/layer.5/ffn/lin1/Add",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/ffn/lin1/MatMul + /transformer/layer.5/ffn/lin1/Add",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 3072,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 3072},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0xde3cb6dda9a9f049",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin1/MatMul]\u001e[ONNX Layer: /transformer/layer.5/ffn/lin1/Add]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin1/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.5/ffn/lin1/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin1/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin1/MatMul]"
},{
  "Name": "PWN(PWN(PWN(PWN(PWN(PWN(PWN(PWN(/transformer/layer.5/ffn/activation/Constant_1_output_0 + ONNXTRT_Broadcast_543, PWN(/transformer/layer.5/ffn/activation/Mul_1)), PWN(/transformer/layer.5/ffn/activation/Mul_2)), PWN(/transformer/layer.5/ffn/activation/Mul_3)), PWN(/transformer/layer.5/ffn/activation/Add)), PWN(/transformer/layer.5/ffn/activation/Constant_2_output_0 + ONNXTRT_Broadcast_545, PWN(/transformer/layer.5/ffn/activation/Mul_4))), PWN(/transformer/layer.5/ffn/activation/Tanh)), PWN(/transformer/layer.5/ffn/activation/Constant_3_output_0 + ONNXTRT_Broadcast_547, PWN(/transformer/layer.5/ffn/activation/Add_1))), PWN(PWN(/transformer/layer.5/ffn/activation/Constant_output_0 + ONNXTRT_Broadcast_541, PWN(/transformer/layer.5/ffn/activation/Mul)), PWN(/transformer/layer.5/ffn/activation/Mul_5)))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin1/Add_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var8"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 8,
  "Literals": ["4.470825e-02f", "7.978516e-01f", "0.000000e+00f", "1.000000e+00f", "0.000000e+00f", "0.000000e+00f", "1.000000e+00f", "5.000000e-01f"],
  "NbOperations": 9,
  "Operations": ["auto const var0 = pwgen::iMul(arg0, literal0);", "auto const var1 = pwgen::iMul(var0, arg0);", "auto const var2 = pwgen::iMul(var1, arg0);", "auto const var3 = pwgen::iPlus(arg0, var2);", "auto const var4 = pwgen::iMul(var3, literal1);", "auto const var5 = pwgen::iTanh(var4);", "auto const var6 = pwgen::iPlus(var5, literal6);", "auto const var7 = pwgen::iMul(arg0, literal7);", "auto const var8 = pwgen::iMul(var7, var6);"],
  "TacticValue": "0x0000000000000009",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/activation/Mul_1]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Mul_2]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Mul_3]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Add]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Mul_4]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Tanh]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Add_1]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Mul]\u001e[ONNX Layer: /transformer/layer.5/ffn/activation/Mul_5]"
},{
  "Name": "reshape_before_/transformer/layer.5/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/ffn/activation/Mul_5_output_0",
    "Location": "Device",
    "Dimensions": [1,128,3072],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to /transformer/layer.5/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_/transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "/transformer/layer.5/ffn/lin2/MatMul",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to /transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,3072,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major Int8 format"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 768,
  "Groups": 1,
  "Weights": {"Type": "Int8", "Count": 2359296},
  "Bias": {"Type": "Float", "Count": 0},
  "HasBias": 0,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1",
  "TacticValue": "0x960e9baa2a6cad5b",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin2/MatMul]"
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin2/MatMul_conv_out",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Thirty-two wide channel vectorized row major FP32 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_after_/transformer/layer.5/ffn/lin2/MatMul",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to reshape_after_/transformer/layer.5/ffn/lin2/MatMul",
    "Location": "Device",
    "Dimensions": [128,768,1,1],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "/transformer/layer.5/ffn/lin2/MatMul_output_0",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin2/MatMul]"
},{
  "Name": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_myl216_0",
  "LayerType": "kgen",
  "Inputs": [
  {
    "Name": "/transformer/layer.5/sa_layer_norm/Add_1_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  },
  {
    "Name": "/transformer/layer.5/ffn/lin2/MatMul_output_0",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Output Tensor 0 to {ForeignNode[transformer.layer.5.ffn.lin2.bias + ONNXTRT_Broadcast_551.../transformer/layer.5/output_layer_norm/Add_1]}",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Float"
  }],
  "TacticName": "__myl_AddAddMeanSubMulMeanAddSqrtDivMulMulAdd_0x670a4620f2fe5ad43611f059b95bbc51",
  "StreamId": 0,
  "Metadata": "[ONNX Layer: /transformer/layer.5/ffn/lin2/Add]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/ReduceMean_1]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Sub]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Pow]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/ReduceMean]\u001f[ONNX Layer: /transformer/layer.5/Add_1]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Div]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Add_1]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Mul]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Sqrt]\u001f[ONNX Layer: /transformer/layer.5/output_layer_norm/Add]"
},{
  "Name": "Reformatting CopyNode for Output Tensor 0 to {ForeignNode[transformer.layer.5.ffn.lin2.bias + ONNXTRT_Broadcast_551.../transformer/layer.5/output_layer_norm/Add_1]}",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "Reformatted Output Tensor 0 to {ForeignNode[transformer.layer.5.ffn.lin2.bias + ONNXTRT_Broadcast_551.../transformer/layer.5/output_layer_norm/Add_1]}",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP32"
  }],
  "Outputs": [
  {
    "Name": "output",
    "Location": "Device",
    "Dimensions": [1,128,768],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
}],
"Bindings": ["input_ids"
,"attention_mask"
,"output"
]}
